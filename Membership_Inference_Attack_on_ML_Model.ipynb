{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch.nn.functional as F\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport os","metadata":{"id":"8orv5ZnNLz8w","execution":{"iopub.status.busy":"2024-06-05T08:19:10.434488Z","iopub.execute_input":"2024-06-05T08:19:10.434810Z","iopub.status.idle":"2024-06-05T08:19:16.715842Z","shell.execute_reply.started":"2024-06-05T08:19:10.434782Z","shell.execute_reply":"2024-06-05T08:19:16.714883Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:21:25.589876Z","iopub.execute_input":"2024-06-05T08:21:25.590235Z","iopub.status.idle":"2024-06-05T08:22:52.905714Z","shell.execute_reply.started":"2024-06-05T08:21:25.590206Z","shell.execute_reply":"2024-06-05T08:22:52.904723Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nChannels:\n - rapidsai\n - nvidia\n - conda-forge\n - defaults\n - pytorch\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - gdown\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2024.6.2   |       hbcca054_0         152 KB  conda-forge\n    filelock-3.14.0            |     pyhd8ed1ab_0          16 KB  conda-forge\n    gdown-5.2.0                |     pyhd8ed1ab_0          21 KB  conda-forge\n    openssl-3.3.1              |       h4ab18f5_0         2.8 MB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         2.9 MB\n\nThe following NEW packages will be INSTALLED:\n\n  filelock           conda-forge/noarch::filelock-3.14.0-pyhd8ed1ab_0 \n  gdown              conda-forge/noarch::gdown-5.2.0-pyhd8ed1ab_0 \n\nThe following packages will be UPDATED:\n\n  ca-certificates                       2024.2.2-hbcca054_0 --> 2024.6.2-hbcca054_0 \n  openssl                                  3.3.0-h4ab18f5_3 --> 3.3.1-h4ab18f5_0 \n\n\n\nDownloading and Extracting Packages:\nopenssl-3.3.1        | 2.8 MB    |                                       |   0% \nca-certificates-2024 | 152 KB    |                                       |   0% \u001b[A\n\ngdown-5.2.0          | 21 KB     |                                       |   0% \u001b[A\u001b[A\n\n\nopenssl-3.3.1        | 2.8 MB    | #                                     |   3% \u001b[A\u001b[A\u001b[A\nca-certificates-2024 | 152 KB    | #######7                              |  21% \u001b[A\n\n\nfilelock-3.14.0      | 16 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\n\ngdown-5.2.0          | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\nca-certificates-2024 | 152 KB    | ##################################### | 100% \u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":" !gdown --id 1U1abPCf3drtdWeLmxfQNFwNDflOzfXYD","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:27:00.508435Z","iopub.execute_input":"2024-06-05T08:27:00.509400Z","iopub.status.idle":"2024-06-05T08:27:24.024224Z","shell.execute_reply.started":"2024-06-05T08:27:00.509358Z","shell.execute_reply":"2024-06-05T08:27:24.023033Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1U1abPCf3drtdWeLmxfQNFwNDflOzfXYD\nFrom (redirected): https://drive.google.com/uc?id=1U1abPCf3drtdWeLmxfQNFwNDflOzfXYD&confirm=t&uuid=fe2d68bb-c86d-4267-a9f8-603aab48f306\nTo: /kaggle/working/amlm_for_kaggle.zip\n100%|███████████████████████████████████████| 2.81G/2.81G [00:21<00:00, 132MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":" ! unzip amlm_for_kaggle.zip","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:28:23.670318Z","iopub.execute_input":"2024-06-05T08:28:23.670708Z","iopub.status.idle":"2024-06-05T08:29:32.073998Z","shell.execute_reply.started":"2024-06-05T08:28:23.670675Z","shell.execute_reply":"2024-06-05T08:29:32.072851Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Archive:  amlm_for_kaggle.zip\n   creating: amlm/\n  inflating: __MACOSX/._amlm         \n  inflating: amlm/.DS_Store          \n  inflating: __MACOSX/amlm/._.DS_Store  \n   creating: amlm/models/\n  inflating: __MACOSX/amlm/._models  \n   creating: amlm/pickle/\n  inflating: __MACOSX/amlm/._pickle  \n  inflating: amlm/models/mobilenetv2_tinyimagenet.pth  \n  inflating: __MACOSX/amlm/models/._mobilenetv2_tinyimagenet.pth  \n  inflating: amlm/models/mobilenetv2_cifar10.pth  \n  inflating: __MACOSX/amlm/models/._mobilenetv2_cifar10.pth  \n  inflating: amlm/models/resnet34_tinyimagenet.pth  \n  inflating: __MACOSX/amlm/models/._resnet34_tinyimagenet.pth  \n  inflating: amlm/models/resnet34_cifar10.pth  \n  inflating: __MACOSX/amlm/models/._resnet34_cifar10.pth  \n  inflating: amlm/pickle/.DS_Store   \n  inflating: __MACOSX/amlm/pickle/._.DS_Store  \n   creating: amlm/pickle/tinyimagenet/\n  inflating: __MACOSX/amlm/pickle/._tinyimagenet  \n   creating: amlm/pickle/cifar10/\n  inflating: __MACOSX/amlm/pickle/._cifar10  \n   creating: amlm/pickle/tinyimagenet/resnet34/\n  inflating: __MACOSX/amlm/pickle/tinyimagenet/._resnet34  \n   creating: amlm/pickle/tinyimagenet/mobilenetv2/\n  inflating: __MACOSX/amlm/pickle/tinyimagenet/._mobilenetv2  \n  inflating: amlm/pickle/tinyimagenet/.DS_Store  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/._.DS_Store  \n   creating: amlm/pickle/cifar10/resnet34/\n  inflating: __MACOSX/amlm/pickle/cifar10/._resnet34  \n   creating: amlm/pickle/cifar10/mobilenetv2/\n  inflating: __MACOSX/amlm/pickle/cifar10/._mobilenetv2  \n  inflating: amlm/pickle/cifar10/.DS_Store  \n  inflating: __MACOSX/amlm/pickle/cifar10/._.DS_Store  \n  inflating: amlm/pickle/tinyimagenet/resnet34/eval.p  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/resnet34/._eval.p  \n  inflating: amlm/pickle/tinyimagenet/resnet34/shadow.p  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/resnet34/._shadow.p  \n  inflating: amlm/pickle/tinyimagenet/resnet34/test.p  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/resnet34/._test.p  \n  inflating: amlm/pickle/tinyimagenet/mobilenetv2/eval.p  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/mobilenetv2/._eval.p  \n  inflating: amlm/pickle/tinyimagenet/mobilenetv2/shadow.p  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/mobilenetv2/._shadow.p  \n  inflating: amlm/pickle/tinyimagenet/mobilenetv2/test.p  \n  inflating: __MACOSX/amlm/pickle/tinyimagenet/mobilenetv2/._test.p  \n  inflating: amlm/pickle/cifar10/resnet34/eval.p  \n  inflating: __MACOSX/amlm/pickle/cifar10/resnet34/._eval.p  \n  inflating: amlm/pickle/cifar10/resnet34/shadow.p  \n  inflating: __MACOSX/amlm/pickle/cifar10/resnet34/._shadow.p  \n  inflating: amlm/pickle/cifar10/resnet34/test.p  \n  inflating: __MACOSX/amlm/pickle/cifar10/resnet34/._test.p  \n  inflating: amlm/pickle/cifar10/mobilenetv2/eval.p  \n  inflating: __MACOSX/amlm/pickle/cifar10/mobilenetv2/._eval.p  \n  inflating: amlm/pickle/cifar10/mobilenetv2/shadow.p  \n  inflating: __MACOSX/amlm/pickle/cifar10/mobilenetv2/._shadow.p  \n  inflating: amlm/pickle/cifar10/mobilenetv2/test.p  \n  inflating: __MACOSX/amlm/pickle/cifar10/mobilenetv2/._test.p  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Define training transformations\nimport torchvision.transforms as transforms\n# Define evaluation transformations\neval_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),  # Convert the images to PyTorch tensors\n    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n])","metadata":{"id":"1CwvbSRxYHge","execution":{"iopub.status.busy":"2024-06-05T10:20:17.245525Z","iopub.execute_input":"2024-06-05T10:20:17.246398Z","iopub.status.idle":"2024-06-05T10:20:17.251249Z","shell.execute_reply.started":"2024-06-05T10:20:17.246367Z","shell.execute_reply":"2024-06-05T10:20:17.250248Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"class ProcessingDataset(torch.utils.data.Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image, label = self.data[idx]\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label","metadata":{"id":"Tgl5WGCpXSi8","execution":{"iopub.status.busy":"2024-06-05T10:20:20.246969Z","iopub.execute_input":"2024-06-05T10:20:20.247309Z","iopub.status.idle":"2024-06-05T10:20:20.254262Z","shell.execute_reply.started":"2024-06-05T10:20:20.247284Z","shell.execute_reply":"2024-06-05T10:20:20.253302Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# Function to load dataset\ndef load_data(file_path, transform=None):\n    with open(file_path, \"rb\") as f:\n        dataset = pickle.load(f)\n    return dataset","metadata":{"id":"BG3NSyobL4na","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(model, dataloader, is_member):\n    model.eval()\n    features = []\n    entropy = 0\n    accuracy = 0\n    with torch.no_grad():\n        for data in dataloader:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            softmax_probabilities = torch.softmax(outputs, dim=1).cpu().detach().numpy()\n\n            \n            for label_id, single_label in enumerate(labels):\n                features.append(softmax_probabilities[label_id].tolist()+[single_label.item()]) #newline\n\n    return features","metadata":{"id":"f3TlsfeJMDes","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Placeholder for is_member function\ndef is_member(data):\n    # Dummy implementation\n    return True","metadata":{"id":"zXyROPWpMHlN","execution":{"iopub.status.busy":"2024-06-05T08:32:14.376539Z","iopub.execute_input":"2024-06-05T08:32:14.376902Z","iopub.status.idle":"2024-06-05T08:32:14.381219Z","shell.execute_reply.started":"2024-06-05T08:32:14.376877Z","shell.execute_reply":"2024-06-05T08:32:14.380330Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"shadow_data_path = '/kaggle/working/amlm/pickle/cifar10/resnet34/shadow.p'\neval_data_path = '/kaggle/working/amlm/pickle/cifar10/resnet34/eval.p'\ntest_data_path = '/kaggle/working/amlm/pickle/cifar10/resnet34/test.p'","metadata":{"id":"Xjo_vUPrMbZa","execution":{"iopub.status.busy":"2024-06-05T08:32:14.808333Z","iopub.execute_input":"2024-06-05T08:32:14.808699Z","iopub.status.idle":"2024-06-05T08:32:14.813273Z","shell.execute_reply.started":"2024-06-05T08:32:14.808647Z","shell.execute_reply":"2024-06-05T08:32:14.812183Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"shadow_dataset = load_data(shadow_data_path)\neval_dataset = load_data(eval_data_path)\ntest_dataset = load_data(test_data_path)","metadata":{"id":"nTn3huDqMlMg","execution":{"iopub.status.busy":"2024-06-05T08:32:16.417407Z","iopub.execute_input":"2024-06-05T08:32:16.418239Z","iopub.status.idle":"2024-06-05T08:32:22.235692Z","shell.execute_reply.started":"2024-06-05T08:32:16.418204Z","shell.execute_reply":"2024-06-05T08:32:22.234912Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(\"Eval Dataset Example: \", eval_dataset[2])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoF6zbFDeCZp","outputId":"ed4e73e4-86ba-4b40-cc9e-9fa84ef32389","execution":{"iopub.status.busy":"2024-06-04T22:04:10.046785Z","iopub.execute_input":"2024-06-04T22:04:10.047149Z","iopub.status.idle":"2024-06-04T22:04:10.133929Z","shell.execute_reply.started":"2024-06-04T22:04:10.047105Z","shell.execute_reply":"2024-06-04T22:04:10.132849Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Eval Dataset Example:  [tensor([[[0.2510, 0.2471, 0.2392,  ..., 0.2353, 0.1804, 0.2000],\n         [0.3059, 0.3059, 0.2784,  ..., 0.1804, 0.1765, 0.1765],\n         [0.3647, 0.3412, 0.3333,  ..., 0.2667, 0.2863, 0.2745],\n         ...,\n         [0.4745, 0.4784, 0.4863,  ..., 0.5412, 0.5098, 0.4471],\n         [0.4745, 0.4784, 0.4824,  ..., 0.4745, 0.4667, 0.4392],\n         [0.4392, 0.4706, 0.4824,  ..., 0.4157, 0.4353, 0.4000]],\n\n        [[0.2902, 0.2667, 0.2392,  ..., 0.2706, 0.2157, 0.2314],\n         [0.3451, 0.3451, 0.3137,  ..., 0.2157, 0.2118, 0.2039],\n         [0.4078, 0.3882, 0.3882,  ..., 0.2980, 0.3176, 0.3020],\n         ...,\n         [0.3961, 0.4000, 0.4078,  ..., 0.4667, 0.4118, 0.3490],\n         [0.3961, 0.4000, 0.4039,  ..., 0.3961, 0.3725, 0.3373],\n         [0.3647, 0.4000, 0.4157,  ..., 0.3451, 0.3490, 0.3098]],\n\n        [[0.2745, 0.2588, 0.2667,  ..., 0.2745, 0.2392, 0.2784],\n         [0.3686, 0.3804, 0.3804,  ..., 0.2392, 0.2471, 0.2627],\n         [0.4627, 0.4588, 0.4745,  ..., 0.3451, 0.3725, 0.3686],\n         ...,\n         [0.2706, 0.2667, 0.2667,  ..., 0.3294, 0.2745, 0.2314],\n         [0.2706, 0.2706, 0.2627,  ..., 0.2549, 0.2353, 0.2275],\n         [0.2627, 0.2863, 0.2980,  ..., 0.2275, 0.2392, 0.2235]]]), 1, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"HEcWtzh1DlZ6","execution":{"iopub.status.busy":"2024-06-05T08:32:32.245990Z","iopub.execute_input":"2024-06-05T08:32:32.246609Z","iopub.status.idle":"2024-06-05T08:32:32.282164Z","shell.execute_reply.started":"2024-06-05T08:32:32.246575Z","shell.execute_reply":"2024-06-05T08:32:32.281086Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Load pre-trained target model\nmodel_path = '/kaggle/working/amlm/models/resnet34_cifar10.pth'\ntarget_model = models.resnet34(num_classes=10).to(device)\nstate_dict = torch.load(model_path, map_location=device)\ntarget_model.load_state_dict(state_dict['net'])\ntarget_model.eval()","metadata":{"id":"JrVAAf-BDpG3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6a9bd8c-63a3-48bf-bd98-0c75404a6ac0","execution":{"iopub.status.busy":"2024-06-05T08:32:33.015276Z","iopub.execute_input":"2024-06-05T08:32:33.015632Z","iopub.status.idle":"2024-06-05T08:32:33.736414Z","shell.execute_reply.started":"2024-06-05T08:32:33.015601Z","shell.execute_reply":"2024-06-05T08:32:33.735456Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define two shadow models with same architecture as target model\n\nshadow_model_A = models.resnet34(weights=None, num_classes=10).to(device)\nshadow_model_B = models.resnet34(weights=None, num_classes=10).to(device) #newline\n","metadata":{"id":"K03ky9lfD-av","execution":{"iopub.status.busy":"2024-06-05T08:32:38.635935Z","iopub.execute_input":"2024-06-05T08:32:38.636298Z","iopub.status.idle":"2024-06-05T08:32:39.472921Z","shell.execute_reply.started":"2024-06-05T08:32:38.636267Z","shell.execute_reply":"2024-06-05T08:32:39.472133Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#setting up both the shadow models here\nnum_epochs = 50\nlearning_rate = 1e-3\nbatch_size = 128\nloss_function = nn.CrossEntropyLoss()\n\noptimizer_A = optim.Adagrad(shadow_model_A.parameters(), lr=learning_rate)\noptimizer_B = optim.RMSprop(shadow_model_B.parameters(), lr=learning_rate)\noptimizers = [optimizer_A,optimizer_B]\n","metadata":{"id":"1YkoJHt3Ukpv","execution":{"iopub.status.busy":"2024-06-05T08:32:41.702246Z","iopub.execute_input":"2024-06-05T08:32:41.702957Z","iopub.status.idle":"2024-06-05T08:32:41.734335Z","shell.execute_reply.started":"2024-06-05T08:32:41.702924Z","shell.execute_reply":"2024-06-05T08:32:41.733382Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:32:43.482213Z","iopub.execute_input":"2024-06-05T08:32:43.482585Z","iopub.status.idle":"2024-06-05T08:32:43.487234Z","shell.execute_reply.started":"2024-06-05T08:32:43.482553Z","shell.execute_reply":"2024-06-05T08:32:43.486164Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#Training loop\nmodel_index=1\nfor shadow_model_being_trained in [shadow_model_A, shadow_model_B]:\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        current_learning_rate = learning_rate\n        # with tqdm(shadow_train_dataloader, unit=\"batch\", leave=False) as detensored_train:\n        \n        #splitting the training and testing dataset for the specific model\n        \n        train_current_shadow_model_dataset, test_current_shadow_model_dataset = train_test_split(shadow_dataset, test_size=15000, train_size=15000, random_state=model_index)\n        \n        #loading the specific datasets\n        \n        current_shadow_model_train_dataloader = DataLoader(ProcessingDataset(train_current_shadow_model_dataset,transform=eval_transform), batch_size=batch_size, shuffle=True, num_workers=2) #newline\n        current_shadow_model_test_dataloader = DataLoader(ProcessingDataset(test_current_shadow_model_dataset,transform=eval_transform), batch_size=batch_size, shuffle=False, num_workers=2) #newline\n        \n        for i, data in enumerate(current_shadow_model_train_dataloader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizers[model_index-1].zero_grad()\n            outputs = shadow_model_being_trained(inputs)\n            loss = loss_function(outputs, labels)\n            loss.backward()\n            optimizers[model_index-1].step()\n\n        \n        running_loss = 0.0\n        #with tqdm(shadow_test_dataloader, unit=\"batch\", leave=False) as detensored_test:\n        pred= []\n        gt = [] #newli\n        for i, data in enumerate(current_shadow_model_test_dataloader, 0):\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizers[model_index-1].zero_grad()\n            outputs = shadow_model_being_trained(inputs)\n            loss = loss_function(outputs, labels)\n            optimizers[model_index-1].step()\n\n            running_loss += loss.item()\n            \n            outputs = torch.argmax(outputs, axis=1).cpu().detach().numpy().reshape(-1)\n            labels = labels.cpu().detach().numpy().reshape(-1)\n            \n            pred.extend(outputs)\n            gt.extend(labels)\n\n            batch_report = classification_report(gt, pred, output_dict=True, zero_division=0)\n        print(f\"[Epoch Validation {epoch + 1}, Batch {i + 1}] loss: {running_loss / len(test_current_shadow_model_dataset)}, Accuracy: {batch_report['accuracy']}]\")\n        \n        running_loss = 0.0\n\n        if (epoch+1) % 20 == 0:\n            current_learning_rate /= 3\n            for parameters in optimizers[model_index-1].param_groups:\n                parameters['lr'] = current_learning_rate\n        #scheduler.step()\n    shadow_model_path =f\"shadowmodelstrained/cifar10/reset34-2/shadow\"\n    os.makedirs(shadow_model_path, exist_ok=True)\n    torch.save(shadow_model_being_trained.state_dict(), f\"{shadow_model_path}/{model_index}_state_dict.pth\")\n    model_index+=1\nprint('Finished Training Shadow Model')","metadata":{"id":"KXj9S-CiFAUF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d3f1522-6873-47e9-945e-3b25423ccf52","execution":{"iopub.status.busy":"2024-06-05T08:32:47.018395Z","iopub.execute_input":"2024-06-05T08:32:47.019079Z","iopub.status.idle":"2024-06-05T08:59:18.791545Z","shell.execute_reply.started":"2024-06-05T08:32:47.019043Z","shell.execute_reply":"2024-06-05T08:59:18.790551Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[Epoch Validation 1, Batch 118] loss: 0.01327156883875529, Accuracy: 0.386]\n[Epoch Validation 2, Batch 118] loss: 0.01284010374546051, Accuracy: 0.4215333333333333]\n[Epoch Validation 3, Batch 118] loss: 0.013101332426071166, Accuracy: 0.44193333333333334]\n[Epoch Validation 4, Batch 118] loss: 0.01404023695786794, Accuracy: 0.4438666666666667]\n[Epoch Validation 5, Batch 118] loss: 0.015768118182818095, Accuracy: 0.43433333333333335]\n[Epoch Validation 6, Batch 118] loss: 0.01714831815560659, Accuracy: 0.44406666666666667]\n[Epoch Validation 7, Batch 118] loss: 0.01881760717233022, Accuracy: 0.42493333333333333]\n[Epoch Validation 8, Batch 118] loss: 0.01924742929935455, Accuracy: 0.44706666666666667]\n[Epoch Validation 9, Batch 118] loss: 0.021163029559453327, Accuracy: 0.4235333333333333]\n[Epoch Validation 10, Batch 118] loss: 0.023489141527811685, Accuracy: 0.41046666666666665]\n[Epoch Validation 11, Batch 118] loss: 0.021756431245803832, Accuracy: 0.4318666666666667]\n[Epoch Validation 12, Batch 118] loss: 0.022984493954976398, Accuracy: 0.4185333333333333]\n[Epoch Validation 13, Batch 118] loss: 0.02270630474090576, Accuracy: 0.4436]\n[Epoch Validation 14, Batch 118] loss: 0.022688658157984414, Accuracy: 0.4428666666666667]\n[Epoch Validation 15, Batch 118] loss: 0.02338296275138855, Accuracy: 0.42806666666666665]\n[Epoch Validation 16, Batch 118] loss: 0.022687139177322388, Accuracy: 0.45166666666666666]\n[Epoch Validation 17, Batch 118] loss: 0.025072283713022867, Accuracy: 0.4305333333333333]\n[Epoch Validation 18, Batch 118] loss: 0.02492417588233948, Accuracy: 0.42406666666666665]\n[Epoch Validation 19, Batch 118] loss: 0.024110446198781332, Accuracy: 0.4382]\n[Epoch Validation 20, Batch 118] loss: 0.02527215828895569, Accuracy: 0.4149333333333333]\n[Epoch Validation 21, Batch 118] loss: 0.023332753483454385, Accuracy: 0.4508]\n[Epoch Validation 22, Batch 118] loss: 0.023469961754480996, Accuracy: 0.4503333333333333]\n[Epoch Validation 23, Batch 118] loss: 0.023555487410227456, Accuracy: 0.45393333333333336]\n[Epoch Validation 24, Batch 118] loss: 0.023525875568389892, Accuracy: 0.45313333333333333]\n[Epoch Validation 25, Batch 118] loss: 0.02346396597226461, Accuracy: 0.4537333333333333]\n[Epoch Validation 26, Batch 118] loss: 0.02352602678934733, Accuracy: 0.4557333333333333]\n[Epoch Validation 27, Batch 118] loss: 0.02364185897509257, Accuracy: 0.45266666666666666]\n[Epoch Validation 28, Batch 118] loss: 0.023612854401270547, Accuracy: 0.45513333333333333]\n[Epoch Validation 29, Batch 118] loss: 0.02368638424873352, Accuracy: 0.45313333333333333]\n[Epoch Validation 30, Batch 118] loss: 0.023833454020818073, Accuracy: 0.453]\n[Epoch Validation 31, Batch 118] loss: 0.023810825125376384, Accuracy: 0.45293333333333335]\n[Epoch Validation 32, Batch 118] loss: 0.023947282330195108, Accuracy: 0.45206666666666667]\n[Epoch Validation 33, Batch 118] loss: 0.024051061662038166, Accuracy: 0.45066666666666666]\n[Epoch Validation 34, Batch 118] loss: 0.023995035282770794, Accuracy: 0.4532]\n[Epoch Validation 35, Batch 118] loss: 0.02404566152890523, Accuracy: 0.45413333333333333]\n[Epoch Validation 36, Batch 118] loss: 0.024216501585642498, Accuracy: 0.4498666666666667]\n[Epoch Validation 37, Batch 118] loss: 0.02426661775906881, Accuracy: 0.45066666666666666]\n[Epoch Validation 38, Batch 118] loss: 0.024133781671524048, Accuracy: 0.45426666666666665]\n[Epoch Validation 39, Batch 118] loss: 0.024293854173024494, Accuracy: 0.45]\n[Epoch Validation 40, Batch 118] loss: 0.02424173086484273, Accuracy: 0.452]\n[Epoch Validation 41, Batch 118] loss: 0.024467979049682616, Accuracy: 0.4558]\n[Epoch Validation 42, Batch 118] loss: 0.024346148951848348, Accuracy: 0.45293333333333335]\n[Epoch Validation 43, Batch 118] loss: 0.024721506277720132, Accuracy: 0.4418666666666667]\n[Epoch Validation 44, Batch 118] loss: 0.024482568566004434, Accuracy: 0.452]\n[Epoch Validation 45, Batch 118] loss: 0.024528736718495685, Accuracy: 0.4514]\n[Epoch Validation 46, Batch 118] loss: 0.024542545652389527, Accuracy: 0.4506]\n[Epoch Validation 47, Batch 118] loss: 0.024533859920501708, Accuracy: 0.4530666666666667]\n[Epoch Validation 48, Batch 118] loss: 0.024561311070124308, Accuracy: 0.4528]\n[Epoch Validation 49, Batch 118] loss: 0.024614900811513265, Accuracy: 0.45193333333333335]\n[Epoch Validation 50, Batch 118] loss: 0.024616023890177408, Accuracy: 0.452]\n[Epoch Validation 1, Batch 118] loss: 0.01784567527770996, Accuracy: 0.24106666666666668]\n[Epoch Validation 2, Batch 118] loss: 0.01570303196112315, Accuracy: 0.33086666666666664]\n[Epoch Validation 3, Batch 118] loss: 0.02310860595703125, Accuracy: 0.15246666666666667]\n[Epoch Validation 4, Batch 118] loss: 0.010831509868303935, Accuracy: 0.5218666666666667]\n[Epoch Validation 5, Batch 118] loss: 0.015439308603604634, Accuracy: 0.3781333333333333]\n[Epoch Validation 6, Batch 118] loss: 0.015602210577329, Accuracy: 0.3958]\n[Epoch Validation 7, Batch 118] loss: 0.010736159833272299, Accuracy: 0.5404]\n[Epoch Validation 8, Batch 118] loss: 0.010940400942166646, Accuracy: 0.5449333333333334]\n[Epoch Validation 9, Batch 118] loss: 0.01119719263712565, Accuracy: 0.5762666666666667]\n[Epoch Validation 10, Batch 118] loss: 0.015894093680381773, Accuracy: 0.4534666666666667]\n[Epoch Validation 11, Batch 118] loss: 0.021187497146924337, Accuracy: 0.3994]\n[Epoch Validation 12, Batch 118] loss: 0.01670405807495117, Accuracy: 0.5152666666666667]\n[Epoch Validation 13, Batch 118] loss: 0.01382235022385915, Accuracy: 0.582]\n[Epoch Validation 14, Batch 118] loss: 0.013211112014452617, Accuracy: 0.6012]\n[Epoch Validation 15, Batch 118] loss: 0.017116990725199382, Accuracy: 0.5524666666666667]\n[Epoch Validation 16, Batch 118] loss: 0.012275963068008423, Accuracy: 0.638]\n[Epoch Validation 17, Batch 118] loss: 0.019472706174850463, Accuracy: 0.5356]\n[Epoch Validation 18, Batch 118] loss: 0.014306215604146322, Accuracy: 0.6181333333333333]\n[Epoch Validation 19, Batch 118] loss: 0.01844600830078125, Accuracy: 0.5666]\n[Epoch Validation 20, Batch 118] loss: 0.018033666038513183, Accuracy: 0.5828]\n[Epoch Validation 21, Batch 118] loss: 0.012790301895141602, Accuracy: 0.6791333333333334]\n[Epoch Validation 22, Batch 118] loss: 0.014463074525197347, Accuracy: 0.671]\n[Epoch Validation 23, Batch 118] loss: 0.015789313983917235, Accuracy: 0.6692]\n[Epoch Validation 24, Batch 118] loss: 0.017637732235590616, Accuracy: 0.6522]\n[Epoch Validation 25, Batch 118] loss: 0.018150358668963116, Accuracy: 0.6528]\n[Epoch Validation 26, Batch 118] loss: 0.016628857135772706, Accuracy: 0.6813333333333333]\n[Epoch Validation 27, Batch 118] loss: 0.020336800384521483, Accuracy: 0.6282]\n[Epoch Validation 28, Batch 118] loss: 0.018260043859481812, Accuracy: 0.6586]\n[Epoch Validation 29, Batch 118] loss: 0.01773254244327545, Accuracy: 0.6731333333333334]\n[Epoch Validation 30, Batch 118] loss: 0.0184925483862559, Accuracy: 0.6664666666666667]\n[Epoch Validation 31, Batch 118] loss: 0.02053268295923869, Accuracy: 0.6422]\n[Epoch Validation 32, Batch 118] loss: 0.020671250104904174, Accuracy: 0.64]\n[Epoch Validation 33, Batch 118] loss: 0.021553450242678324, Accuracy: 0.6240666666666667]\n[Epoch Validation 34, Batch 118] loss: 0.017454316552480063, Accuracy: 0.6764666666666667]\n[Epoch Validation 35, Batch 118] loss: 0.021656674551963805, Accuracy: 0.6223333333333333]\n[Epoch Validation 36, Batch 118] loss: 0.018083148741722108, Accuracy: 0.6776]\n[Epoch Validation 37, Batch 118] loss: 0.01909093721707662, Accuracy: 0.667]\n[Epoch Validation 38, Batch 118] loss: 0.019680970088640847, Accuracy: 0.664]\n[Epoch Validation 39, Batch 118] loss: 0.01842128663857778, Accuracy: 0.6787333333333333]\n[Epoch Validation 40, Batch 118] loss: 0.018353642932573955, Accuracy: 0.681]\n[Epoch Validation 41, Batch 118] loss: 0.019658131631215412, Accuracy: 0.6692666666666667]\n[Epoch Validation 42, Batch 118] loss: 0.018595617826779685, Accuracy: 0.6764666666666667]\n[Epoch Validation 43, Batch 118] loss: 0.018957458353042602, Accuracy: 0.6774]\n[Epoch Validation 44, Batch 118] loss: 0.01932794619401296, Accuracy: 0.6754]\n[Epoch Validation 45, Batch 118] loss: 0.019929981931050618, Accuracy: 0.6655333333333333]\n[Epoch Validation 46, Batch 118] loss: 0.019400000659624734, Accuracy: 0.6760666666666667]\n[Epoch Validation 47, Batch 118] loss: 0.01940493830839793, Accuracy: 0.6674666666666667]\n[Epoch Validation 48, Batch 118] loss: 0.01958535876274109, Accuracy: 0.6597333333333333]\n[Epoch Validation 49, Batch 118] loss: 0.018098384157816567, Accuracy: 0.6765333333333333]\n[Epoch Validation 50, Batch 118] loss: 0.01920027800401052, Accuracy: 0.6729333333333334]\nFinished Training Shadow Model\n","output_type":"stream"}]},{"cell_type":"code","source":"\nattack_model_training_data = []\nfor model_index in [1,2]:\n    \n    train_current_shadow_model_dataset, test_current_shadow_model_dataset = train_test_split(shadow_dataset, test_size=15000, train_size=15000, random_state=model_index)\n        \n        #loading the specific datasets\n        \n    current_shadow_model_train_dataloader = DataLoader(train_current_shadow_model_dataset, batch_size=100, shuffle=False, num_workers=2) #newline\n    current_shadow_model_test_dataloader = DataLoader(test_current_shadow_model_dataset, batch_size=100, shuffle=False, num_workers=2) #newline\n\n    model = models.resnet34(weights=None, num_classes=10).to(device)\n    model.load_state_dict(torch.load(f\"shadowmodelstrained/cifar10/reset34-2/shadow/{model_index}_state_dict.pth\", map_location=device))\n    \n    shadow_train_features = extract_features(model, current_shadow_model_train_dataloader, True)\n    shadow_test_features = extract_features(model, current_shadow_model_test_dataloader, False)\n    \n    #combining them both in a single array\n    \n    print(\"Loop for model index\")\n    \n    attack_model_training_data.append({0:shadow_test_features, 1:shadow_train_features}) #0 representing the sample that were not in the shadow model training set\n                                                                                                                       #1 representing the samples that were in the shadow model training set\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:59:25.539107Z","iopub.execute_input":"2024-06-05T09:59:25.539464Z","iopub.status.idle":"2024-06-05T09:59:37.014647Z","shell.execute_reply.started":"2024-06-05T09:59:25.539437Z","shell.execute_reply":"2024-06-05T09:59:37.013461Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Loop for model index\nLoop for model index\n","output_type":"stream"}]},{"cell_type":"code","source":"attack_dataset = []\nfor single_attack_model_data in [attack_model_training_data[0], attack_model_training_data[1]]: #attack_train_data:\n    for single_class in single_attack_model_data:\n        for single_class_id in range(len(single_attack_model_data[single_class])):\n            groundtruth = single_attack_model_data[single_class][single_class_id][-1]\n            logits = sorted(single_attack_model_data[single_class][single_class_id][:-1], reverse=True)\n            attack_dataset.append([[groundtruth]+logits, single_class])\n\nnp.random.seed(0)\nnp.random.shuffle(attack_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:59:54.111205Z","iopub.execute_input":"2024-06-05T09:59:54.112217Z","iopub.status.idle":"2024-06-05T09:59:54.334736Z","shell.execute_reply.started":"2024-06-05T09:59:54.112178Z","shell.execute_reply":"2024-06-05T09:59:54.333714Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"print(\"attack_dataset\" , attack_dataset[0])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:47:48.672811Z","iopub.execute_input":"2024-06-05T00:47:48.673746Z","iopub.status.idle":"2024-06-05T00:47:48.678870Z","shell.execute_reply.started":"2024-06-05T00:47:48.673713Z","shell.execute_reply":"2024-06-05T00:47:48.677831Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"attack_dataset [[3, 0.9385873079299927, 0.04229780659079552, 0.013360838405787945, 0.001624826341867447, 0.0015265177935361862, 0.0012836003443226218, 0.0006053110118955374, 0.00047176997759379447, 0.00018788175657391548, 5.415191481006332e-05], 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"class AttackModel(nn.Module):\n    def __init__(self):\n        super(AttackModel, self).__init__()\n        self.fc1 = nn.Linear(11, 128)  # Increase number of neurons\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 1)\n        self.dropout = nn.Dropout(0.5)  # Dropout layer with 50% dropout rate\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)  # Apply dropout\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)  # Apply dropout\n        x = torch.sigmoid(self.fc3(x))\n        return x","metadata":{"id":"Lm4Pu7Zlnkyr","execution":{"iopub.status.busy":"2024-06-05T11:25:14.210240Z","iopub.execute_input":"2024-06-05T11:25:14.210724Z","iopub.status.idle":"2024-06-05T11:25:14.218749Z","shell.execute_reply.started":"2024-06-05T11:25:14.210663Z","shell.execute_reply":"2024-06-05T11:25:14.217718Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"attack_model = AttackModel().to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(attack_model.parameters(), lr= learning_rate)  # L2 regularization\n","metadata":{"id":"wOmQ7ONsnnJr","execution":{"iopub.status.busy":"2024-06-05T11:25:17.734095Z","iopub.execute_input":"2024-06-05T11:25:17.734605Z","iopub.status.idle":"2024-06-05T11:25:17.745345Z","shell.execute_reply.started":"2024-06-05T11:25:17.734567Z","shell.execute_reply":"2024-06-05T11:25:17.744018Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"class ListingAttackData(torch.utils.data.Dataset):\n\tdef __init__(self, train_dataset):\n\t\tself.X = train_dataset\n\n\tdef __getitem__(self, index):\n\t\tx, y = self.X[index]\n\t\treturn torch.tensor(x), torch.tensor(y).unsqueeze(0).type(torch.float)\n\n\tdef __len__(self):\n\t\treturn len(self.X)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:25:35.255307Z","iopub.execute_input":"2024-06-05T11:25:35.256097Z","iopub.status.idle":"2024-06-05T11:25:35.262250Z","shell.execute_reply.started":"2024-06-05T11:25:35.256060Z","shell.execute_reply":"2024-06-05T11:25:35.261216Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"# Training loop for attack model\n# num_epochs = 10\n\nattack_model_train_dataset, attack_model_test_dataset = train_test_split(attack_dataset, test_size=2000, train_size=28000, random_state=0)\nnum_epochs = 20\n\nattack_model_train_loader = DataLoader(ListingAttackData(attack_model_train_dataset),batch_size=256,shuffle=True)\n\nattack_model_test_loader = DataLoader(ListingAttackData(attack_model_test_dataset),batch_size=256,shuffle=False)\n\n    \nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    accuracy = 0.0\n    for i, (inputs, labels) in enumerate(attack_model_train_loader, 0):\n        #inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = attack_model(inputs)\n    # print(\"outputs at every batch\", outputs)\n    \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        accuracy += torch.sum((outputs[:, 0] > 0.5) == labels[:, 0])\n       \n        #print(\"Train outputs[:, 0]\" , outputs[:, 0])\n        #print(\"Train labels[:, 0]\" , labels[:, 0])\n    print(f'Train: [Epoch {epoch + 1}, Batch {i + 1}] attack model loss: {running_loss / len(attack_model_train_loader)}, Accuracy: {accuracy/len(attack_model_train_dataset)}')\n    #running_loss = 0.0\n        \n        #print(\"Helloooo\")\n    running_loss = 0.0\n    accuracy = 0.0\n    for i, (inputs,labels) in enumerate(attack_model_test_loader, 0):\n        #inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = attack_model(inputs)\n        #print(\"inputs at every batch\", inputs)\n        #print(\"labels at every batch\", labels)\n    \n        loss = criterion(outputs, labels)\n        #loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        accuracy += torch.sum((outputs[:, 0] > 0.5) == labels[:, 0])\n        \n    print(f'Test: [Epoch {epoch + 1}, Batch {i + 1}] attack model loss: {running_loss / len(attack_model_test_loader)}, Accuracy: {accuracy/len(attack_model_test_dataset)}')\n    #running_loss = 0.0\n\nprint('Finished Training Attack Model')","metadata":{"id":"1MGxX5jcnqks","colab":{"base_uri":"https://localhost:8080/","height":400},"outputId":"aebcc587-52e1-4516-fdca-466328decdbb","execution":{"iopub.status.busy":"2024-06-05T11:26:08.244338Z","iopub.execute_input":"2024-06-05T11:26:08.244740Z","iopub.status.idle":"2024-06-05T11:26:28.465503Z","shell.execute_reply.started":"2024-06-05T11:26:08.244709Z","shell.execute_reply":"2024-06-05T11:26:28.464514Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"Train: [Epoch 1, Batch 110] attack model loss: 0.6970094886693088, Accuracy: 0.5018928647041321\nTest: [Epoch 1, Batch 8] attack model loss: 0.6933811157941818, Accuracy: 0.5024999976158142\nTrain: [Epoch 2, Batch 110] attack model loss: 0.6931287489154122, Accuracy: 0.5010356903076172\nTest: [Epoch 2, Batch 8] attack model loss: 0.6926376894116402, Accuracy: 0.5024999976158142\nTrain: [Epoch 3, Batch 110] attack model loss: 0.690972777930173, Accuracy: 0.5013214349746704\nTest: [Epoch 3, Batch 8] attack model loss: 0.6867517158389091, Accuracy: 0.5090000033378601\nTrain: [Epoch 4, Batch 110] attack model loss: 0.6836022582921115, Accuracy: 0.5158928632736206\nTest: [Epoch 4, Batch 8] attack model loss: 0.6792454496026039, Accuracy: 0.5320000052452087\nTrain: [Epoch 5, Batch 110] attack model loss: 0.6773661320859735, Accuracy: 0.5396785736083984\nTest: [Epoch 5, Batch 8] attack model loss: 0.6720754131674767, Accuracy: 0.5585000514984131\nTrain: [Epoch 6, Batch 110] attack model loss: 0.6721374506300146, Accuracy: 0.5659642815589905\nTest: [Epoch 6, Batch 8] attack model loss: 0.6717000305652618, Accuracy: 0.6180000305175781\nTrain: [Epoch 7, Batch 110] attack model loss: 0.6681493087248369, Accuracy: 0.6032857298851013\nTest: [Epoch 7, Batch 8] attack model loss: 0.6648916751146317, Accuracy: 0.6155000329017639\nTrain: [Epoch 8, Batch 110] attack model loss: 0.6652296283028343, Accuracy: 0.6277856826782227\nTest: [Epoch 8, Batch 8] attack model loss: 0.667302593588829, Accuracy: 0.6845000386238098\nTrain: [Epoch 9, Batch 110] attack model loss: 0.6627913583408702, Accuracy: 0.6529642939567566\nTest: [Epoch 9, Batch 8] attack model loss: 0.6593673899769783, Accuracy: 0.6895000338554382\nTrain: [Epoch 10, Batch 110] attack model loss: 0.658655373616652, Accuracy: 0.6799643039703369\nTest: [Epoch 10, Batch 8] attack model loss: 0.6571067795157433, Accuracy: 0.6360000371932983\nTrain: [Epoch 11, Batch 110] attack model loss: 0.6577219876376066, Accuracy: 0.6880714297294617\nTest: [Epoch 11, Batch 8] attack model loss: 0.6530891135334969, Accuracy: 0.6940000057220459\nTrain: [Epoch 12, Batch 110] attack model loss: 0.6548028328201988, Accuracy: 0.6944642663002014\nTest: [Epoch 12, Batch 8] attack model loss: 0.652640588581562, Accuracy: 0.7125000357627869\nTrain: [Epoch 13, Batch 110] attack model loss: 0.6536749574271116, Accuracy: 0.7043214440345764\nTest: [Epoch 13, Batch 8] attack model loss: 0.6536976397037506, Accuracy: 0.737000048160553\nTrain: [Epoch 14, Batch 110] attack model loss: 0.6528361483053727, Accuracy: 0.7014642953872681\nTest: [Epoch 14, Batch 8] attack model loss: 0.6535917595028877, Accuracy: 0.721500039100647\nTrain: [Epoch 15, Batch 110] attack model loss: 0.6515276253223419, Accuracy: 0.7176071405410767\nTest: [Epoch 15, Batch 8] attack model loss: 0.6490198820829391, Accuracy: 0.7220000624656677\nTrain: [Epoch 16, Batch 110] attack model loss: 0.6510144325819882, Accuracy: 0.7191785573959351\nTest: [Epoch 16, Batch 8] attack model loss: 0.651274748146534, Accuracy: 0.749500036239624\nTrain: [Epoch 17, Batch 110] attack model loss: 0.6494262955405495, Accuracy: 0.718500018119812\nTest: [Epoch 17, Batch 8] attack model loss: 0.6487554609775543, Accuracy: 0.7580000162124634\nTrain: [Epoch 18, Batch 110] attack model loss: 0.6505671891299161, Accuracy: 0.7181071639060974\nTest: [Epoch 18, Batch 8] attack model loss: 0.6473793908953667, Accuracy: 0.7535000443458557\nTrain: [Epoch 19, Batch 110] attack model loss: 0.6486537570303137, Accuracy: 0.7279285788536072\nTest: [Epoch 19, Batch 8] attack model loss: 0.6491987109184265, Accuracy: 0.749500036239624\nTrain: [Epoch 20, Batch 110] attack model loss: 0.6480236676606265, Accuracy: 0.7363928556442261\nTest: [Epoch 20, Batch 8] attack model loss: 0.6458703204989433, Accuracy: 0.7240000367164612\nFinished Training Attack Model\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{"id":"lGFAXkbZE7KG"}},{"cell_type":"code","source":"attack_model.eval()\ncorrect = 0\ntotal = 0\nfor sample in eval_dataset:\n    image_input = sample[0].to(device)\n    logits = torch.softmax(target_model(image_input.unsqueeze(0)), dim=1)[0]\n    logits = sorted(logits.cpu().detach().numpy().tolist(), reverse=True)\n\n    member_or_not = attack_model(torch.tensor([[sample[1]]+logits]).to(device))[0][0]\n    member_or_not = member_or_not.cpu().detach().numpy() > 0.55\n    if(member_or_not==sample[2]):\n        correct+=1\n    total+=1\n    \nprint(\"Accuracy on evaluation: \" , 100 * correct/total , \"%\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T11:26:55.831467Z","iopub.execute_input":"2024-06-05T11:26:55.832253Z","iopub.status.idle":"2024-06-05T11:26:57.167407Z","shell.execute_reply.started":"2024-06-05T11:26:55.832215Z","shell.execute_reply":"2024-06-05T11:26:57.166437Z"},"trusted":true},"execution_count":150,"outputs":[{"name":"stdout","text":"Accuracy on evaluation:  74.5 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"W-_SLhgOqC-U"},"execution_count":null,"outputs":[]}]}